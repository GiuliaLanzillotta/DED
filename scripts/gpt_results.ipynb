{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/pub/hofmann-scratch/glanzillo/ded\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import importlib\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import socket\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "internal_path = os.path.abspath(os.path.join('.'))\n",
    "sys.path.append(internal_path)\n",
    "sys.path.append(internal_path + '/datasets')\n",
    "sys.path.append(internal_path + '/utils')\n",
    "\n",
    "import datetime\n",
    "import uuid\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import setproctitle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import json\n",
    "import wandb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from matplotlib.collections import LineCollection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mglanzillo\u001b[0m (\u001b[33mcontinually\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10 runs\n"
     ]
    }
   ],
   "source": [
    "os.environ['WANDB_API_KEY'] = 'c7314b16e17009f66f3043c0b7968e1142054123'\n",
    "wandb.login()\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(path='continually/DataEfficientDistillation', filters={'tags': 'useful'})\n",
    "print(\"Loaded\", len(runs), \"runs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QUERY',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_include_sweeps',\n",
       " '_load_page',\n",
       " '_sweeps',\n",
       " 'client',\n",
       " 'convert_objects',\n",
       " 'cursor',\n",
       " 'entity',\n",
       " 'filters',\n",
       " 'index',\n",
       " 'last_response',\n",
       " 'length',\n",
       " 'more',\n",
       " 'next',\n",
       " 'objects',\n",
       " 'order',\n",
       " 'per_page',\n",
       " 'project',\n",
       " 'update_variables',\n",
       " 'variables']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_attrs',\n",
       " '_base_dir',\n",
       " '_entity',\n",
       " '_exec',\n",
       " '_files',\n",
       " '_full_history',\n",
       " '_include_sweeps',\n",
       " '_repr_html_',\n",
       " '_sampled_history',\n",
       " '_state',\n",
       " '_summary',\n",
       " 'client',\n",
       " 'create',\n",
       " 'delete',\n",
       " 'dir',\n",
       " 'display',\n",
       " 'entity',\n",
       " 'file',\n",
       " 'files',\n",
       " 'history',\n",
       " 'id',\n",
       " 'json_config',\n",
       " 'lastHistoryStep',\n",
       " 'load',\n",
       " 'log_artifact',\n",
       " 'logged_artifacts',\n",
       " 'name',\n",
       " 'path',\n",
       " 'project',\n",
       " 'save',\n",
       " 'scan_history',\n",
       " 'snake_to_camel',\n",
       " 'state',\n",
       " 'storage_id',\n",
       " 'summary',\n",
       " 'sweep',\n",
       " 'to_html',\n",
       " 'update',\n",
       " 'upload_file',\n",
       " 'url',\n",
       " 'use_artifact',\n",
       " 'used_artifacts',\n",
       " 'user',\n",
       " 'username',\n",
       " 'wait_until_finished']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(runs.objects[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['mse', 'sgd', 'seed', 'alpha', 'debug', 'h_dim', 'device', 'exp_id', 'max_lr', 'min_lr', 'compile', 'dataset', 'mlp_dim', 'n_heads', 'seq_len', 'exp_name', 'head_dim', 'log_path', 'n_layers', 'data_root', 'n_workers', 'use_flash', 'eval_every', 'vocab_size', 'decay_steps', 'logger_type', 'temperature', 'wandb_notes', 'project_path', 'grad_clip_norm', 'log_ckpt_every', 'max_eval_steps', 'eval_batch_size', 'log_grads_every', 'max_train_steps', 'test_batch_size', 'train_batch_size', 'log_metrics_every', 'relative_log_path', 'tokens_per_second', 'wandb_entity_name', 'log_terminal_every', 'wandb_project_name', 'log_alignments_every', 'log_activations_every', 'teacher_checkpoint_path', 'gradient_accumulation_steps'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = json.loads(runs.objects[0].json_config)\n",
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['seed']['value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_step</th>\n",
       "      <th>config</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>parameter count</th>\n",
       "      <th>parameter count without embedding</th>\n",
       "      <th>eval_batches</th>\n",
       "      <th>eval_tokens</th>\n",
       "      <th>eval_bytes</th>\n",
       "      <th>_train/tokens_seen</th>\n",
       "      <th>...</th>\n",
       "      <th>_eval/normalised_ppl_over_tokens</th>\n",
       "      <th>_eval/normalised_loss</th>\n",
       "      <th>_eval/normalised_ppl_over_gpuseconds</th>\n",
       "      <th>x_axes/gpu_seconds</th>\n",
       "      <th>_time/tokens_per_second</th>\n",
       "      <th>_eval/normalised_loss_over_gpuseconds</th>\n",
       "      <th>_eval/ppl_over_gpuseconds</th>\n",
       "      <th>_train/loss</th>\n",
       "      <th>_time/iterations_per_second</th>\n",
       "      <th>_eval/top10_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>{'size': 1390, '_latest_artifact_path': 'wandb...</td>\n",
       "      <td>9.283063</td>\n",
       "      <td>1.705768e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.298753</td>\n",
       "      <td>1.705768e+09</td>\n",
       "      <td>27549696.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.298922</td>\n",
       "      <td>1.705768e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10772480.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.049116</td>\n",
       "      <td>1.705768e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.049463</td>\n",
       "      <td>1.705768e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4096000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _step                                             config   _runtime  \\\n",
       "0      0  {'size': 1390, '_latest_artifact_path': 'wandb...   9.283063   \n",
       "1      1                                                NaN   9.298753   \n",
       "2      2                                                NaN   9.298922   \n",
       "3      3                                                NaN  46.049116   \n",
       "4      4                                                NaN  46.049463   \n",
       "\n",
       "     _timestamp  parameter count  parameter count without embedding  \\\n",
       "0  1.705768e+09              NaN                                NaN   \n",
       "1  1.705768e+09       27549696.0                                NaN   \n",
       "2  1.705768e+09              NaN                         10772480.0   \n",
       "3  1.705768e+09              NaN                                NaN   \n",
       "4  1.705768e+09              NaN                                NaN   \n",
       "\n",
       "   eval_batches  eval_tokens  eval_bytes  _train/tokens_seen  ...  \\\n",
       "0           NaN          NaN         NaN                 NaN  ...   \n",
       "1           NaN          NaN         NaN                 NaN  ...   \n",
       "2           NaN          NaN         NaN                 NaN  ...   \n",
       "3         500.0          NaN         NaN                 NaN  ...   \n",
       "4           NaN    4096000.0         NaN                 NaN  ...   \n",
       "\n",
       "   _eval/normalised_ppl_over_tokens  _eval/normalised_loss  \\\n",
       "0                               NaN                    NaN   \n",
       "1                               NaN                    NaN   \n",
       "2                               NaN                    NaN   \n",
       "3                               NaN                    NaN   \n",
       "4                               NaN                    NaN   \n",
       "\n",
       "   _eval/normalised_ppl_over_gpuseconds  x_axes/gpu_seconds  \\\n",
       "0                                   NaN                 NaN   \n",
       "1                                   NaN                 NaN   \n",
       "2                                   NaN                 NaN   \n",
       "3                                   NaN                 NaN   \n",
       "4                                   NaN                 NaN   \n",
       "\n",
       "   _time/tokens_per_second  _eval/normalised_loss_over_gpuseconds  \\\n",
       "0                      NaN                                    NaN   \n",
       "1                      NaN                                    NaN   \n",
       "2                      NaN                                    NaN   \n",
       "3                      NaN                                    NaN   \n",
       "4                      NaN                                    NaN   \n",
       "\n",
       "   _eval/ppl_over_gpuseconds  _train/loss  _time/iterations_per_second  \\\n",
       "0                        NaN          NaN                          NaN   \n",
       "1                        NaN          NaN                          NaN   \n",
       "2                        NaN          NaN                          NaN   \n",
       "3                        NaN          NaN                          NaN   \n",
       "4                        NaN          NaN                          NaN   \n",
       "\n",
       "   _eval/top10_acc  \n",
       "0              NaN  \n",
       "1              NaN  \n",
       "2              NaN  \n",
       "3              NaN  \n",
       "4              NaN  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = runs.objects[0].history()\n",
    "h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_step', 'config', '_runtime', '_timestamp', 'parameter count',\n",
       "       'parameter count without embedding', 'eval_batches', 'eval_tokens',\n",
       "       'eval_bytes', '_train/tokens_seen', '_train/learning_rate_0',\n",
       "       '_eval/total_loss', '_eval/top10_acc_over_gpuseconds', '_eval/ppl',\n",
       "       '_eval/fa', '_eval/ppl_over_tokens',\n",
       "       '_eval/normalised_loss_over_tokens', '_eval/top1_acc_over_tokens',\n",
       "       'x_axes/n_tokens', '_time/forward', '_time/eval',\n",
       "       '_eval/top1_acc_over_gpuseconds', '_eval/top10_acc_over_tokens',\n",
       "       '_eval/cka', '_eval/loss', '_time/train_step', '_time/total_step',\n",
       "       '_train/cka', '_time/backward', '_train/fa', '_eval/normalised_ppl',\n",
       "       '_eval/top1_acc', '_time/load_batch',\n",
       "       '_eval/normalised_ppl_over_tokens', '_eval/normalised_loss',\n",
       "       '_eval/normalised_ppl_over_gpuseconds', 'x_axes/gpu_seconds',\n",
       "       '_time/tokens_per_second', '_eval/normalised_loss_over_gpuseconds',\n",
       "       '_eval/ppl_over_gpuseconds', '_train/loss',\n",
       "       '_time/iterations_per_second', '_eval/top10_acc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.40231186151504517,\n",
       " 0.5032689571380615,\n",
       " 0.5224665403366089,\n",
       " 0.536484956741333,\n",
       " 0.5498769283294678,\n",
       " 0.5514689087867737,\n",
       " 0.5602566003799438,\n",
       " 0.5614172220230103,\n",
       " 0.5586612820625305,\n",
       " 0.5795760750770569,\n",
       " 0.5739375352859497,\n",
       " 0.5710100531578064,\n",
       " 0.5867127776145935,\n",
       " 0.5773130059242249,\n",
       " 0.5850902199745178,\n",
       " 0.591157078742981,\n",
       " 0.592695415019989,\n",
       " 0.5914744734764099,\n",
       " 0.6026270389556885,\n",
       " 0.5916302800178528,\n",
       " 0.592689573764801,\n",
       " 0.5996255874633789,\n",
       " 0.6005229949951172,\n",
       " 0.6010473966598511,\n",
       " 0.6057960391044617,\n",
       " 0.6048132181167603,\n",
       " 0.6079581379890442,\n",
       " 0.6118248701095581,\n",
       " 0.6088635325431824,\n",
       " 0.6044564843177795,\n",
       " 0.6107466220855713,\n",
       " 0.6121087670326233,\n",
       " 0.623515784740448,\n",
       " 0.6232402324676514,\n",
       " 0.6092463135719299,\n",
       " 0.6210176944732666,\n",
       " 0.6167471408843994,\n",
       " 0.6087719798088074,\n",
       " 0.6146456599235535,\n",
       " 0.6195009350776672,\n",
       " 0.6198665499687195,\n",
       " 0.616502046585083,\n",
       " 0.6148177981376648,\n",
       " 0.6190458536148071,\n",
       " 0.6199896931648254,\n",
       " 0.6132553815841675,\n",
       " 0.6244933009147644,\n",
       " 0.6061812043190002,\n",
       " 0.6102924346923828,\n",
       " 0.6197707653045654,\n",
       " 0.615190863609314,\n",
       " 0.623797595500946,\n",
       " 0.6175651550292969,\n",
       " 0.6228331327438354,\n",
       " 0.6244058609008789,\n",
       " 0.6189720630645752,\n",
       " 0.6159141659736633,\n",
       " 0.6213064789772034,\n",
       " 0.6173146367073059,\n",
       " 0.6229760646820068,\n",
       " 0.6245139241218567,\n",
       " 0.6288391351699829,\n",
       " 0.6278673410415649,\n",
       " 0.6205509305000305,\n",
       " 0.6361693739891052,\n",
       " 0.6383743286132812,\n",
       " 0.6366727948188782,\n",
       " 0.6293733716011047,\n",
       " 0.6300233006477356,\n",
       " 0.6342822909355164,\n",
       " 0.642044723033905,\n",
       " 0.622793436050415,\n",
       " 0.630533754825592,\n",
       " 0.6325476765632629,\n",
       " 0.6330550909042358,\n",
       " 0.6274797320365906,\n",
       " 0.6445960998535156,\n",
       " 0.6297696828842163,\n",
       " 0.6355438828468323,\n",
       " 0.6283459663391113,\n",
       " 0.6364089846611023,\n",
       " 0.6381834149360657,\n",
       " 0.6477901935577393,\n",
       " 0.640826940536499,\n",
       " 0.6407577395439148,\n",
       " 0.64384925365448,\n",
       " 0.6412638425827026,\n",
       " 0.6424219012260437,\n",
       " 0.643688440322876,\n",
       " 0.6396036148071289,\n",
       " 0.6418759226799011,\n",
       " 0.6298548579216003,\n",
       " 0.6297253966331482,\n",
       " 0.6356538534164429,\n",
       " 0.6469942331314087,\n",
       " 0.6369569897651672,\n",
       " 0.649057924747467,\n",
       " 0.6492979526519775,\n",
       " 0.6433515548706055,\n",
       " 0.6374378800392151,\n",
       " 0.6418106555938721,\n",
       " 0.6431873440742493,\n",
       " 0.63710618019104,\n",
       " 0.646014392375946,\n",
       " 0.6428093314170837,\n",
       " 0.6467447876930237,\n",
       " 0.6486528515815735,\n",
       " 0.6505153775215149,\n",
       " 0.6466559767723083,\n",
       " 0.6431186199188232,\n",
       " 0.6452969312667847,\n",
       " 0.6454530358314514,\n",
       " 0.6470838189125061,\n",
       " 0.6449066996574402,\n",
       " 0.6435694098472595,\n",
       " 0.6451192498207092,\n",
       " 0.6447453498840332,\n",
       " 0.6555076241493225,\n",
       " 0.6446585059165955,\n",
       " 0.6513537764549255,\n",
       " 0.6536975502967834,\n",
       " 0.6539285182952881,\n",
       " 0.6529321670532227,\n",
       " 0.6497679948806763,\n",
       " 0.6451481580734253,\n",
       " 0.6479848623275757,\n",
       " 0.6458200216293335,\n",
       " 0.6556823253631592,\n",
       " 0.6501032114028931,\n",
       " 0.6516523957252502,\n",
       " 0.6493934988975525,\n",
       " 0.6517351865768433,\n",
       " 0.6500818729400635,\n",
       " 0.6540848016738892,\n",
       " 0.6518638730049133,\n",
       " 0.6533373594284058,\n",
       " 0.6516136527061462,\n",
       " 0.649935245513916,\n",
       " 0.6510862112045288,\n",
       " 0.646673321723938,\n",
       " 0.652445912361145,\n",
       " 0.652251124382019,\n",
       " 0.6550024747848511,\n",
       " 0.6534309387207031,\n",
       " 0.6529542207717896,\n",
       " 0.6540032625198364,\n",
       " 0.6535035371780396,\n",
       " 0.6454556584358215,\n",
       " 0.6512919664382935,\n",
       " 0.6524344682693481,\n",
       " 0.6496961116790771,\n",
       " 0.6488727331161499,\n",
       " 0.6483936905860901,\n",
       " 0.6551697850227356,\n",
       " 0.6549031734466553,\n",
       " 0.651836097240448,\n",
       " 0.6518941521644592,\n",
       " 0.6516233086585999,\n",
       " 0.6530490517616272,\n",
       " 0.6530376672744751,\n",
       " 0.6528023481369019,\n",
       " 0.6519375443458557,\n",
       " 0.6507448554039001,\n",
       " 0.647670328617096,\n",
       " 0.6563373804092407,\n",
       " 0.654073178768158,\n",
       " 0.6489908695220947,\n",
       " 0.6523817181587219,\n",
       " 0.6508191227912903,\n",
       " 0.652239978313446,\n",
       " 0.6516909003257751,\n",
       " 0.653523862361908,\n",
       " 0.6499550342559814,\n",
       " 0.6572917699813843,\n",
       " 0.6559587717056274,\n",
       " 0.6543900966644287,\n",
       " 0.6536126136779785,\n",
       " 0.6547406911849976,\n",
       " 0.6523868441581726,\n",
       " 0.6514837145805359,\n",
       " 0.6616678237915039,\n",
       " 0.6530356407165527,\n",
       " 0.6562081575393677,\n",
       " 0.6504900455474854,\n",
       " 0.6491538882255554,\n",
       " 0.6462231278419495,\n",
       " 0.6461698412895203,\n",
       " 0.6474618315696716,\n",
       " 0.6501375436782837,\n",
       " 0.6503527164459229,\n",
       " 0.6495445370674133,\n",
       " 0.6491775512695312,\n",
       " 0.6494523882865906,\n",
       " 0.6493556499481201,\n",
       " 0.6502015590667725,\n",
       " 0.6472158432006836,\n",
       " 0.6461722254753113,\n",
       " 0.6461259126663208,\n",
       " 0.6522987484931946,\n",
       " 0.6419620513916016,\n",
       " 0.6496331095695496,\n",
       " 0.649482250213623,\n",
       " 0.6490934491157532,\n",
       " 0.6447846293449402,\n",
       " 0.6476479768753052,\n",
       " 0.6480473279953003,\n",
       " 0.643658459186554,\n",
       " 0.6454775929450989,\n",
       " 0.6465274691581726,\n",
       " 0.6491311192512512,\n",
       " 0.6495946049690247,\n",
       " 0.648354709148407,\n",
       " 0.6494856476783752,\n",
       " 0.6546858549118042,\n",
       " 0.6527550220489502,\n",
       " 0.6480138301849365,\n",
       " 0.6510049104690552,\n",
       " 0.6481373906135559,\n",
       " 0.6486766934394836,\n",
       " 0.6485797762870789,\n",
       " 0.6468568444252014,\n",
       " 0.6475703716278076,\n",
       " 0.6476126909255981,\n",
       " 0.6492660641670227,\n",
       " 0.6470283269882202,\n",
       " 0.6461569666862488,\n",
       " 0.6439882516860962,\n",
       " 0.6399732232093811,\n",
       " 0.6475868821144104,\n",
       " 0.6463268399238586,\n",
       " 0.6450116634368896,\n",
       " 0.6418032050132751,\n",
       " 0.6411965489387512,\n",
       " 0.6410180926322937,\n",
       " 0.6444065570831299,\n",
       " 0.6457749009132385,\n",
       " 0.6420865058898926,\n",
       " 0.6478403806686401,\n",
       " 0.6475534439086914,\n",
       " 0.6469700932502747,\n",
       " 0.6463228464126587,\n",
       " 0.6430884003639221,\n",
       " 0.6392489075660706,\n",
       " 0.6481576561927795,\n",
       " 0.6404309272766113,\n",
       " 0.6448779106140137,\n",
       " 0.644349992275238,\n",
       " 0.6410765051841736,\n",
       " 0.6371793746948242,\n",
       " 0.640660285949707,\n",
       " 0.6431920528411865,\n",
       " 0.6438156962394714,\n",
       " 0.6449294686317444,\n",
       " 0.6413282752037048,\n",
       " 0.6378228068351746,\n",
       " 0.643017053604126,\n",
       " 0.636425256729126,\n",
       " 0.6385841369628906,\n",
       " 0.6397660970687866,\n",
       " 0.6429530382156372,\n",
       " 0.644999623298645,\n",
       " 0.6410983800888062,\n",
       " 0.642279863357544,\n",
       " 0.640741229057312,\n",
       " 0.643072247505188,\n",
       " 0.6357774138450623,\n",
       " 0.6344608068466187,\n",
       " 0.6378975510597229,\n",
       " 0.6366393566131592,\n",
       " 0.6362597942352295,\n",
       " 0.6340467929840088,\n",
       " 0.6318719983100891,\n",
       " 0.6335641145706177,\n",
       " 0.6282768845558167,\n",
       " 0.6341150999069214,\n",
       " 0.6357623338699341,\n",
       " 0.6353898048400879,\n",
       " 0.6341363191604614,\n",
       " 0.6390030980110168,\n",
       " 0.6392809152603149,\n",
       " 0.6362610459327698,\n",
       " 0.6409043073654175,\n",
       " 0.6350909471511841,\n",
       " 0.6295501589775085,\n",
       " 0.6384745836257935,\n",
       " 0.6322415471076965,\n",
       " 0.6318512558937073,\n",
       " 0.631332516670227,\n",
       " 0.6306318640708923,\n",
       " 0.6305330395698547,\n",
       " 0.6306200623512268,\n",
       " 0.6271854639053345,\n",
       " 0.634152352809906,\n",
       " 0.6291337013244629,\n",
       " 0.6284664869308472,\n",
       " 0.6344166398048401,\n",
       " 0.6306871175765991,\n",
       " 0.6278762817382812,\n",
       " 0.6271683573722839,\n",
       " 0.6239322423934937,\n",
       " 0.6257184743881226,\n",
       " 0.626416802406311,\n",
       " 0.6209055185317993,\n",
       " 0.6246861815452576,\n",
       " 0.6233862042427063,\n",
       " 0.6295844316482544,\n",
       " 0.6287904977798462,\n",
       " 0.631086528301239,\n",
       " 0.6264902949333191,\n",
       " 0.6223660111427307,\n",
       " 0.6250951886177063,\n",
       " 0.6244099736213684,\n",
       " 0.6262467503547668,\n",
       " 0.6245507001876831,\n",
       " 0.6263149380683899,\n",
       " 0.6221964359283447,\n",
       " 0.6259130835533142,\n",
       " 0.6231350898742676,\n",
       " 0.616875171661377,\n",
       " 0.6188716888427734,\n",
       " 0.6157072186470032,\n",
       " 0.6192414164543152,\n",
       " 0.621396541595459,\n",
       " 0.6180166006088257,\n",
       " 0.6130822896957397,\n",
       " 0.613116979598999,\n",
       " 0.6222345232963562,\n",
       " 0.6191664934158325,\n",
       " 0.6245141625404358,\n",
       " 0.6204138398170471,\n",
       " 0.6173824667930603,\n",
       " 0.6191794872283936,\n",
       " 0.6251381635665894,\n",
       " 0.6189865469932556,\n",
       " 0.6166138052940369,\n",
       " 0.6180323958396912,\n",
       " 0.6188790202140808,\n",
       " 0.6198731660842896,\n",
       " 0.620685338973999,\n",
       " 0.6146233677864075,\n",
       " 0.6183322072029114,\n",
       " 0.6189553737640381,\n",
       " 0.620503306388855,\n",
       " 0.618209719657898,\n",
       " 0.6153313517570496,\n",
       " 0.6121635437011719,\n",
       " 0.6126968860626221,\n",
       " 0.6185070276260376,\n",
       " 0.6178305745124817,\n",
       " 0.6193519830703735,\n",
       " 0.6123471856117249,\n",
       " 0.6210005283355713,\n",
       " 0.6132426261901855,\n",
       " 0.6174792647361755,\n",
       " 0.6175491213798523,\n",
       " 0.6177718639373779,\n",
       " 0.6133714318275452,\n",
       " 0.6128544807434082,\n",
       " 0.6143550276756287,\n",
       " 0.6165492534637451,\n",
       " 0.6084683537483215,\n",
       " 0.6115618944168091,\n",
       " 0.6080740094184875,\n",
       " 0.6067758202552795,\n",
       " 0.6097462177276611,\n",
       " 0.6027669906616211,\n",
       " 0.6100489497184753,\n",
       " 0.6071591377258301,\n",
       " 0.6076280474662781]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(h[6:]['_eval/cka'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLUMNS = ['alpha','seed','student_net','teacher_net','step',\n",
    "           'tokens_seen','cka_val','cka_train','fa_val','fa_train',\n",
    "           'val_acc_top1', 'val_acc_top10', 'loss_train', 'ppl_val']\n",
    "res_df = pd.DataFrame(columns=COLUMNS)\n",
    "\n",
    "for run in runs.objects:\n",
    "    h = run.history()[6:] # first rows are for validation\n",
    "    config = json.loads(run.json_config)\n",
    "    total = len(h)\n",
    "    new_runs = '_eval/cka' in h.columns\n",
    "    sub_df = pd.DataFrame({\"alpha\":[config['alpha']['value']]*total,\n",
    "                           \"seed\":[config['seed']['value']]*total,\n",
    "                           #\"student_net\":[]*total, #TODO: add tag\n",
    "                           #\"teacher_net\":[]*total,\n",
    "                           \"step\":list(h['_step']),\n",
    "                           \"tokens_seen\":list(h['_train/tokens_seen']),\n",
    "                           \"cka_val\": list(h['_eval/cka']) if new_runs else [-1]*total ,\n",
    "                           \"cka_train\":list(h['_train/cka']) if new_runs else [-1]*total,\n",
    "                           \"fa_val\":list(h['_eval/fa']) if new_runs else [-1]*total,\n",
    "                           \"fa_train\":list(h['_train/fa']) if new_runs else [-1]*total,\n",
    "                           \"val_acc_top1\":list(h['_eval/top1_acc']),\n",
    "                           \"val_acc_top10\":list(h['_eval/top1_acc']),\n",
    "                           \"loss_train\":list(h['_train/loss']),\n",
    "                           \"ppl_val\":list(h['_eval/ppl'])\n",
    "                        })\n",
    "    res_df = pd.concat([res_df,sub_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "alpha                      1\n",
       "seed                      55\n",
       "student_net              NaN\n",
       "teacher_net              NaN\n",
       "step                    6600\n",
       "tokens_seen      432603136.0\n",
       "cka_val             0.679556\n",
       "cka_train           0.712425\n",
       "fa_val              0.004591\n",
       "fa_train             0.00477\n",
       "val_acc_top1        0.331598\n",
       "val_acc_top10       0.331598\n",
       "loss_train          3.467307\n",
       "ppl_val             39.10051\n",
       "Name: 1000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.iloc[1000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_API_KEY'] = '1d1281bc805ce7f60b937c3a9874b8eae6a20c20'\n",
    "import wandb\n",
    "wandb.login()\n",
    "api = wandb.Api()\n",
    "runs = api.runs(path='bobby-he/gpt', filters={'tags': 'useful'})\n",
    "losses_dict = {}\n",
    "xaxis='runtime'\n",
    "for run in runs:\n",
    "    if \"skipless\" in run.metadata['args'][0]:\n",
    "        if \"parallel\" in run.metadata['args'][0]:\n",
    "            name = \"SAS-P\"\n",
    "        else:\n",
    "            name = \"SAS\"\n",
    "    else:\n",
    "        if \"parallel\" in run.metadata['args'][0]:\n",
    "            name = \"Parallel\"\n",
    "        else:\n",
    "            name = \"Pre-LN\"\n",
    "    losses=run._full_history(samples=10000)\n",
    "    eval_losses = [loss for loss in losses if \"_eval/ppl\" in loss and loss['_eval/ppl'] is not None]\n",
    "    eval_xaxis = [loss['_runtime']/3600  if xaxis == \"runtime\" else loss[\"train/global_step\"] for loss in eval_losses]\n",
    "    eval_losses = [loss['_eval/ppl'] for loss in eval_losses]\n",
    "    losses_dict[name] = (eval_xaxis, eval_losses)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
